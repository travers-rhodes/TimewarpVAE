{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6388b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.857097Z",
     "start_time": "2023-09-29T02:51:44.302683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travers/miniconda3/envs/timewarpvae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timewarp_lib.vector_timewarpers as vtw\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f690e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.878711Z",
     "start_time": "2023-09-29T02:51:45.858710Z"
    }
   },
   "outputs": [],
   "source": [
    "tau = 1\n",
    "yzero = 0\n",
    "\n",
    "# arbitrary?\n",
    "alpha_z = 10\n",
    "beta_z = alpha_z/4\n",
    "\n",
    "N = 50\n",
    "sigma = 2/N\n",
    "\n",
    "def phase_func(t):\n",
    "    phasefactor = -np.log(0.01)\n",
    "    return np.exp(-t * phasefactor)\n",
    "\n",
    "cs = phase_func(np.linspace(0,1,N,endpoint=True))\n",
    "\n",
    "fulldat = np.load(\"../data/trainTest2DLetterACache.npz\")\n",
    "fulldat[\"train\"].shape\n",
    "dat = fulldat[\"train\"]\n",
    "numdims = dat.shape[2]\n",
    "numts = dat.shape[1]\n",
    "numtrajs = dat.shape[0]\n",
    "\n",
    "\n",
    "ts = np.linspace(0,1,numts)\n",
    "xs = phase_func(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef41c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.884188Z",
     "start_time": "2023-09-29T02:51:45.879840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yeah, i don't _really_ get it, but an original Ijspeert paper\n",
    "# (and the Learning Parametric Dynamic Movement... paper)\n",
    "# have the forcing term affect velocity, not acceleration\n",
    "def numeric_integration(ydemos, ts, tau, g, alpha_z, beta_z):\n",
    "    step_size = 0.00001\n",
    "    i = 0\n",
    "    t = ts[i]\n",
    "    i += 1\n",
    "    z = 0\n",
    "    zs = []\n",
    "    zs.append(z)\n",
    "    while i < len(ts):\n",
    "        while i < len(ts) and t < ts[i]:\n",
    "            interp_frac = (t - ts[i-1])/(ts[i] - ts[i-1])\n",
    "            y = (1-interp_frac) * ydemos[i-1] + interp_frac * ydemos[i]\n",
    "            z += alpha_z * (beta_z * (g - y) - z)/tau * step_size\n",
    "            t += step_size\n",
    "        zs.append(z)\n",
    "        i += 1\n",
    "    return np.array(zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd9ae2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.888898Z",
     "start_time": "2023-09-29T02:51:45.886067Z"
    }
   },
   "outputs": [],
   "source": [
    "# basisphis, targetfunction, xs are all evaluated at ts\n",
    "def fit_target_i(i, basisphis, targetfunction, xs, yzero, g):\n",
    "    s = xs * (g - yzero)\n",
    "    gamma = np.diag(basisphis[i])\n",
    "    # equation 2.14 from Dynamical Movement Primitives: Learning Attractor Models for Motor Behaviors\n",
    "    numerator = s @ gamma @ targetfunction\n",
    "    denominator = s @ gamma @ s\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bfd633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.894486Z",
     "start_time": "2023-09-29T02:51:45.890402Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(fitted_f, ts, g, alpha_z, beta_z):\n",
    "    step_size = 0.00001\n",
    "    i = 0\n",
    "    t = ts[i]\n",
    "    ys = [] # position\n",
    "    zs = [] # velocity\n",
    "    y = 0\n",
    "    z = 0\n",
    "    t = 0\n",
    "    while i < len(ts):\n",
    "        while i < len(ts) and t < ts[i]:\n",
    "            interp_frac = (t - ts[i-1])/(ts[i] - ts[i-1])\n",
    "            f = (1-interp_frac) * fitted_f[i-1] + interp_frac * fitted_f[i]\n",
    "            z += alpha_z * (beta_z * (g - y) - z)/tau * step_size\n",
    "            y += (z + f)/tau * step_size\n",
    "            t += step_size\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "        i += 1\n",
    "    return (np.array(ys), np.array(zs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f8fe8",
   "metadata": {},
   "source": [
    "## Compute DTW parameterization of each training trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e6f557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T02:51:45.900894Z",
     "start_time": "2023-09-29T02:51:45.895786Z"
    }
   },
   "outputs": [],
   "source": [
    "# traj should be 2d\n",
    "def compute_dtw_parameterization(traj):\n",
    "    assert len(traj.shape) == 2, \"traj should be 2d...just send in one\"\n",
    "    start_offset_0, start_offset_1 = traj[0]\n",
    "    ydemos = traj-traj[0:1]\n",
    "    result_dictionary = {}\n",
    "    for dim in range(2):\n",
    "        ydemo = ydemos[:,dim]\n",
    "        ydemoprime = (ydemo[2:]-ydemo[:-2])/(ts[1]-ts[0])/2\n",
    "        ydemoprime = np.concatenate(((ydemo[1:2]-ydemo[:1])/(ts[1]-ts[0]),ydemoprime,(ydemo[-1:]-ydemo[-2:-1])/(ts[1]-ts[0])))\n",
    "        yzero = ydemo[0]\n",
    "        g = ydemo[-1]\n",
    "        basisphis = np.array([np.exp(-(phase_func(ts) - c)**2/((sigma * c)**2)) for c in cs])\n",
    "        zdemo = numeric_integration(ydemo, ts, tau, g, alpha_z, beta_z)\n",
    "        ftarget = tau * ydemoprime - zdemo\n",
    "        ws = np.array([fit_target_i(i, basisphis, ftarget, xs, yzero, g) for i in range(len(basisphis))])\n",
    "        result_dictionary[f\"ws_{dim}\"] = ws\n",
    "        result_dictionary[f\"g_{dim}\"] = g\n",
    "    result_dictionary[f\"start_offset_0\"] = start_offset_0\n",
    "    result_dictionary[f\"start_offset_1\"] = start_offset_1\n",
    "    return result_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dda4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee586eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T03:05:14.653928Z",
     "start_time": "2023-09-29T02:51:45.901966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n"
     ]
    }
   ],
   "source": [
    "important_results_object = []\n",
    "for i in range(len(dat)):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    result_dictionary = compute_dtw_parameterization(dat[i])\n",
    "    important_results_object.append(result_dictionary)\n",
    "    \n",
    "parameters_vector = np.array([np.concatenate((dic[\"ws_0\"],dic[\"ws_1\"],\n",
    "                                    [dic[\"start_offset_0\"],dic[\"start_offset_1\"],\n",
    "                                    dic[\"g_0\"],dic[\"g_1\"]]\n",
    "                                   ))\n",
    "                     for dic in important_results_object])\n",
    "\n",
    "np.save(\"parameters_vector_dmps.npy\", parameters_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258dc12c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T03:05:14.659670Z",
     "start_time": "2023-09-29T03:05:14.655301Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_parameter_vector(parameter_vector):\n",
    "    ws_0 = parameter_vector[:N]\n",
    "    ws_1 = parameter_vector[N:2*N]\n",
    "    start_offset_0,start_offset_1,g_0,g_1 = parameter_vector[2*N:]\n",
    "    basisphis = np.array([np.exp(-(phase_func(ts) - c)**2/((sigma * c)**2)) for c in cs])\n",
    "    \n",
    "    positions = []\n",
    "    for g,ws,start_offset in [(g_0,ws_0,start_offset_0), (g_1,ws_1,start_offset_1)]:\n",
    "        yzero=0 # centered training data all starts at zero\n",
    "        fitted_f = np.einsum(\"it,i->t\",basisphis,ws)/np.einsum(\"it->t\",basisphis) * xs * (g-yzero)\n",
    "        # ys = position, zs = velocity\n",
    "        ys,zs = simulate(fitted_f,ts,g,alpha_z,beta_z)\n",
    "        positions.append(ys + start_offset)\n",
    "    positions=np.array(positions).T\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29558dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a790d70e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T04:53:17.765379Z",
     "start_time": "2023-09-29T04:53:17.761042Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_dmp_parameter_model(training_data, latent_dim,scale_last_four_dims=1):\n",
    "    num_trajs, num_channels = training_data.shape\n",
    "    print(f\"we have num_trajs:{num_trajs}, num_channels:{num_channels}\")\n",
    "    flattened_trajs = np.copy(training_data)\n",
    "    \n",
    "    flattened_trajs[:,-4:] = flattened_trajs[:,-4:] * scale_last_four_dims\n",
    "\n",
    "    # compute and remove the mean trajectory (mean trajectory is of shape (num_timesteps * num_channels))\n",
    "    mean_traj = np.mean(flattened_trajs, axis=0)\n",
    "    centered_trajs = flattened_trajs - mean_traj[np.newaxis,:]\n",
    "\n",
    "    # compute the PCA model using SVD\n",
    "    u, s, vt = np.linalg.svd(centered_trajs)\n",
    "\n",
    "    # keep only the first latent_dim number of dimensions\n",
    "    if len(s) < latent_dim:\n",
    "        raise Exception(f\"You can't build a model of dimension {latent_dim} on a dataset with dimensionality {len(s)}\")\n",
    "\n",
    "    # the singular values written in matrix form\n",
    "    smat = np.diag(s[:latent_dim])\n",
    "    smatinv = np.diag(1./s[:latent_dim])\n",
    "    # the first latent_dim directions of variation\n",
    "    basis_vectors = vt[:latent_dim,:]\n",
    "    # given a trajectory, use this to find its value in the latent space \n",
    "    # note that the dimensions of the embedding matrix are (latent_dim, nt*nc)\n",
    "    embedding_matrix = smatinv @ basis_vectors \n",
    "    # note that we include the s factor here so that our latent space is roughly the unit gaussian ball :brain:\n",
    "    # note further that the dimensions of the reconstruction matrix are also (latent_dim, nt*nc)\n",
    "    reconstruction_matrix = smat @ basis_vectors\n",
    "\n",
    "    return {\n",
    "      \"num_trajs\" : num_trajs, \n",
    "      \"num_channels\" : num_channels,\n",
    "      \"latent_dim\" : latent_dim,\n",
    "      \"mean_traj\" : mean_traj,\n",
    "      \"embedding_matrix\" : embedding_matrix,\n",
    "      \"reconstruction_matrix\" : reconstruction_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f765e9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T04:53:19.195385Z",
     "start_time": "2023-09-29T04:53:19.188685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a ModelApplier object based purely on a\n",
    "# directory containing model information\n",
    "class ModelApplier(object):\n",
    "    def __init__(self, modeldata):\n",
    "        self.num_trajs = modeldata[\"num_trajs\"]\n",
    "        self.num_channels = modeldata[\"num_channels\"]\n",
    "        self.latent_dim = modeldata[\"latent_dim\"]\n",
    "        self.mean_traj = modeldata[\"mean_traj\"]\n",
    "        self.embedding_matrix = modeldata[\"embedding_matrix\"]\n",
    "        self.reconstruction_matrix = modeldata[\"reconstruction_matrix\"]\n",
    "\n",
    "    # The input data should be of the shape\n",
    "    # (num_apply_trajs, apply_latent_dim)\n",
    "    def apply(self, data):\n",
    "        num_apply_trajs, apply_latent_dim = data.shape\n",
    "        if apply_latent_dim != self.latent_dim:\n",
    "              raise Exception(f\"The number of latent dim coordinates given: {apply_latent_dim} was not the same as the {self.latent_dim} expected by the model\")\n",
    "\n",
    "        # compute the linear combination of basis vectors \n",
    "        traj_offset_vectors = data @ self.reconstruction_matrix\n",
    "        mean_vector = self.mean_traj.reshape(1,self.num_channels)\n",
    "        # add back the mean vector\n",
    "        traj_vectors = traj_offset_vectors + mean_vector\n",
    "        # reshape to the official standard expected shape\n",
    "        # (num_apply_trajs, num_timesteps, num_channels)\n",
    "        result_trajs = traj_vectors.reshape(num_apply_trajs, self.num_channels)\n",
    "        return result_trajs\n",
    "\n",
    "    # The input data should be of the shape\n",
    "    # (num_apply_trajs, self.num_timesteps, self.num_channels)\n",
    "    # The output latent dimensions are of the shape\n",
    "    # (num_apply_trajs, self.latent_dim)\n",
    "    def embed(self, data):\n",
    "        num_apply_trajs, apply_num_channels = data.shape\n",
    "        assert apply_num_channels == self.num_channels, \"channels must match for PCA\"\n",
    "\n",
    "        flattened_trajs = data\n",
    "        mean_vector = self.mean_traj.reshape(1,self.num_channels)\n",
    "        centered_trajs = flattened_trajs - mean_vector\n",
    "        # the dimensions of the embedding matrix are (latent_dim, nt*nc)\n",
    "        latent_vals_mat = centered_trajs @ self.embedding_matrix.T\n",
    "        return(latent_vals_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb66821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T04:53:19.345287Z",
     "start_time": "2023-09-29T04:53:19.338120Z"
    }
   },
   "outputs": [],
   "source": [
    "test_time_dtw_vector_timewarper = vtw.DTWVectorTimewarper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdcf225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T04:53:22.061319Z",
     "start_time": "2023-09-29T04:53:22.050202Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_trip_loss(ma, traj, i,scale_last_four_dims=1):\n",
    "    assert len(traj.shape) == 2, \"pass in one traj at a time\"\n",
    "    num_ts, channels = traj.shape\n",
    "    assert channels == 2, \"2 channels for handwriting\"\n",
    "    dic = compute_dtw_parameterization(traj)\n",
    "    params = np.concatenate((dic[\"ws_0\"],dic[\"ws_1\"],\n",
    "                                    [dic[\"start_offset_0\"],dic[\"start_offset_1\"],\n",
    "                                    dic[\"g_0\"],dic[\"g_1\"]]\n",
    "                                   )).reshape(1,-1)\n",
    "    params[:,-4:] = scale_last_four_dims * params[:,-4:]\n",
    "    new_parameters = ma.apply(ma.embed(params))\n",
    "    new_parameters[0][-4:] = new_parameters[0][-4:]/scale_last_four_dims\n",
    "    pos = decode_parameter_vector(new_parameters[0])\n",
    "    recon_train = pos.reshape((1,num_ts, channels))\n",
    "    train = traj.reshape((1,num_ts, channels))\n",
    "    \n",
    "    train_dtw_recon, train_dtw_actual = test_time_dtw_vector_timewarper.timewarp_first_and_second(\n",
    "        torch.tensor(recon_train,dtype=torch.float), \n",
    "        torch.tensor(train,dtype=torch.float))\n",
    "    train_aligned_loss = (\n",
    "        nn.functional.mse_loss(train_dtw_recon, train_dtw_actual, reduction=\"sum\").detach().numpy()\n",
    "        / (num_ts))\n",
    "    train_error = np.sum(np.square(recon_train - train))/(num_ts)\n",
    "    \n",
    "    squareresults = (ma.latent_dim, train_aligned_loss, train_error, i)\n",
    "    return squareresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c354477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T04:53:27.971894Z",
     "start_time": "2023-09-29T04:53:22.939483Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have num_trajs:3750, num_channels:104\n",
      "we have num_trajs:3750, num_channels:104\n",
      "we have num_trajs:3750, num_channels:104\n",
      "we have num_trajs:3750, num_channels:104\n"
     ]
    }
   ],
   "source": [
    "for latent_dim in range(1,5):\n",
    "    vals = train_dmp_parameter_model(parameters_vector,latent_dim,scale_last_four_dims=100)\n",
    "    np.savez(f\"dmpmodels/parametric_dmp_{latent_dim}.npz\", dic=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d31ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T05:05:11.569956Z",
     "start_time": "2023-09-29T04:57:42.227538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "running a dataset\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# we trained on augmented data, but we should just apply to regular data\n",
    "\n",
    "DATAFILE=f\"../data/trainTest2DLetterARescaled.npz\"\n",
    "data = np.load(DATAFILE)\n",
    "test = data[\"test\"]\n",
    "train = data[\"train\"]\n",
    "\n",
    "num_trains, num_ts, channels = train.shape\n",
    "num_tests, num_ts, channels = test.shape\n",
    "\n",
    "for latent_dim in range(1,5):\n",
    "    vals = np.load(f\"dmpmodels/parametric_dmp_{latent_dim}.npz\",allow_pickle=True)[\"dic\"].item()\n",
    "    ma = ModelApplier(vals)\n",
    "    all_results = []\n",
    "    for dataset in [train, test]:\n",
    "        print(\"running a dataset\")\n",
    "        square_losses = []\n",
    "        for i in range(len(dataset)):\n",
    "            if i % 10 == 0:\n",
    "                print(i)\n",
    "            square_losses.append(round_trip_loss(ma, dataset[i], i,scale_last_four_dims=100))\n",
    "        square_losses = np.array(square_losses)\n",
    "        all_results.append(square_losses)\n",
    "    np.savez(f\"intermediate_dmp_error_results_{latent_dim}.npz\",train=all_results[0], test=all_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588737d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T05:05:11.603458Z",
     "start_time": "2023-09-29T05:05:11.571894Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results = []\n",
    "for latent_dim in range(1,17):\n",
    "    intermediate_results = np.load(f\"intermediate_dmp_error_results_{latent_dim}.npz\")\n",
    "    valid_inds = intermediate_results[\"train\"][:,0] == latent_dim\n",
    "    if np.sum(valid_inds) != 125:\n",
    "        continue\n",
    "    ld,train_aligned_loss, train_error, checkval = np.mean(intermediate_results[\"train\"][valid_inds,],axis=0)\n",
    "    assert ld == latent_dim, \"check your latent_dim\"\n",
    "    assert checkval == 62, \"should have indices ranging from 0 to 124\"\n",
    "    \n",
    "    valid_inds = intermediate_results[\"test\"][:,0] == latent_dim\n",
    "    latent_dim,test_aligned_loss, test_error, checkval = np.mean(intermediate_results[\"test\"][valid_inds,],axis=0)\n",
    "    assert ld == latent_dim, \"check your latent_dim\"\n",
    "    assert checkval == 62, \"should have indices ranging from 0 to 124\"\n",
    "    \n",
    "    final_results.append((latent_dim, np.sqrt(train_aligned_loss),np.sqrt(test_aligned_loss), \n",
    "                       np.sqrt(train_error), np.sqrt(test_error)))\n",
    "final_results = np.array(final_results)\n",
    "np.savez(\"dmp_results.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05868d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T05:05:11.609136Z",
     "start_time": "2023-09-29T05:05:11.604799Z"
    }
   },
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14310a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T03:35:36.398465Z",
     "start_time": "2023-09-29T03:35:35.668801Z"
    }
   },
   "outputs": [],
   "source": [
    "pos1 = decode_parameter_vector(parameters_vector[10])\n",
    "pos2 = decode_parameter_vector((parameters_vector[15] + parameters_vector[10])/2)\n",
    "pos3 = decode_parameter_vector(parameters_vector[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a23f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T03:35:36.674685Z",
     "start_time": "2023-09-29T03:35:36.400118Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pos in [pos1, pos2, pos3]:\n",
    "    plt.plot(pos[:,0],pos[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4657e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
