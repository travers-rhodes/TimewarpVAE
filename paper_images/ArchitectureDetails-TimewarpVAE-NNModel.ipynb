{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9725c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.619243Z",
     "start_time": "2023-09-27T14:36:06.987341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travers/miniconda3/envs/timewarpvae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timewarp_lib.load_model as lm\n",
    "import timewarp_lib.train_utils as tu\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e13f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LoadedModel(\"../results/rescaled/20231011-003229.166126/savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d6d6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = lm.LoadedModel(\"../results/retrainedforkdata/20230928-065206.641930/savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1d6bd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.624218Z",
     "start_time": "2023-09-27T14:36:13.621445Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce12cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_modeldata_info = np.load(\"../forkdata/forkTrajectoryData.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ceb85c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 200, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fork_test_data = fork_modeldata_info[\"test\"]\n",
    "fork_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feb24802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.630664Z",
     "start_time": "2023-09-27T14:36:13.628445Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "####clean_model_dirs = [\"../results/overnight/20230921-093159.705744/savedmodel\"] # TenDTWModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2bc02d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.637330Z",
     "start_time": "2023-09-27T14:36:13.635016Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58ce2f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.666030Z",
     "start_time": "2023-09-27T14:36:13.638892Z"
    }
   },
   "outputs": [],
   "source": [
    "datatype = \"train\"\n",
    "dtype=torch.float\n",
    "device=\"cpu\"\n",
    "batch_size=100\n",
    "training_data_timing_noise=0\n",
    "\n",
    "dataName = \"../data/trainTest2DLetterARescaled.npz\"\n",
    "# the datafile has information on how the data was cleaned\n",
    "# the learned/applied model is on clean data\n",
    "# so we need to convert back to trajectory data\n",
    "loaded_data_dict = np.load(dataName)\n",
    "\n",
    "ydata = torch.tensor(loaded_data_dict[datatype],dtype=dtype).to(device)\n",
    "np_ydata = ydata.detach().cpu().numpy()\n",
    "num_trajs, numts, traj_channels = ydata.shape\n",
    "tdata = torch.tensor(np.linspace(0,1,numts),dtype=dtype).to(device).expand(num_trajs,numts).unsqueeze(2)\n",
    "\n",
    "torch_train_data = torch.utils.data.TensorDataset(tdata, ydata)\n",
    "training_dataloader = torch.utils.data.DataLoader(torch_train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b097888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 200, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fbfffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeledParameterScalarTimewarper(\n",
       "  (timewarp_parameter_encoder): OneDConvEncoder(\n",
       "    (fcmu): Linear(in_features=1408, out_features=50, bias=True)\n",
       "    (fclogvar): Linear(in_features=1408, out_features=50, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (nonlinearity): ReLU()\n",
       "    (emb_convs): ModuleList(\n",
       "      (0): Conv1d(2, 16, kernel_size=(3,), stride=(1,))\n",
       "      (1): Conv1d(16, 32, kernel_size=(3,), stride=(2,))\n",
       "      (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "      (3): Conv1d(32, 64, kernel_size=(3,), stride=(2,))\n",
       "      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      (5): Conv1d(64, 64, kernel_size=(3,), stride=(2,))\n",
       "    )\n",
       "    (emb_fcs): ModuleList()\n",
       "  )\n",
       "  (LogSoftmaxLayer): LogSoftmax(dim=1)\n",
       "  (monotonic_applier): ParameterizedMonotonicApplier()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.scalar_timewarper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4c4d724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplicatedFunctionStyleDecoder(\n",
       "  (motion_model): TemplateMotionGeneration(\n",
       "    (nonlinearity): ELU(alpha=1.0)\n",
       "    (all_layers): ModuleList(\n",
       "      (0): Linear(in_features=1, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): Linear(in_features=500, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (nonlinearity): ELU(alpha=1.0)\n",
       "  (all_side_layers): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d9e21bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transpose torch.Size([2, 200, 2])\n",
      "after transpose torch.Size([2, 2, 200])\n",
      "did convolution  torch.Size([2, 16, 198])\n",
      "did convolution  torch.Size([2, 32, 98])\n",
      "did convolution  torch.Size([2, 64, 48])\n",
      "did convolution  torch.Size([2, 32, 23])\n",
      "flattened torch.Size([2, 736])\n",
      "final torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "emb = model.model.encoder.encode(ydata[(0,1),],tdata[(0,1),])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c6cc3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transpose torch.Size([2, 200, 2])\n",
      "after transpose torch.Size([2, 2, 200])\n",
      "did convolution  torch.Size([2, 16, 198])\n",
      "did convolution  torch.Size([2, 32, 98])\n",
      "did convolution  torch.Size([2, 32, 96])\n",
      "did convolution  torch.Size([2, 64, 47])\n",
      "did convolution  torch.Size([2, 64, 45])\n",
      "did convolution  torch.Size([2, 64, 22])\n",
      "flattened torch.Size([2, 1408])\n",
      "final torch.Size([2, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9532, -0.2034,  0.3342,  0.4481,  0.3413,  0.5072,  0.5424,  0.5480,\n",
       "          0.3798,  0.1958,  0.0779, -0.0119,  0.1796,  0.2761,  0.4575,  0.5816,\n",
       "          0.5991,  0.6518,  0.4834,  0.4685,  0.4266,  0.4544,  0.5001,  0.5344,\n",
       "          0.6760,  0.7994,  0.8417,  0.8305,  0.8506,  0.8199,  0.8189,  0.6181,\n",
       "          0.6393,  0.6508,  0.7593,  0.7562,  0.6575,  0.4780,  0.3167,  0.0570,\n",
       "          0.0675,  0.0561, -0.1871,  0.0088, -0.1459,  0.0286,  0.0778, -0.2034,\n",
       "          0.1688, -0.2595],\n",
       "        [-0.7832, -0.1565,  0.0728,  0.0595, -0.1389, -0.0803,  0.3789,  0.5212,\n",
       "          0.6676,  0.6181,  0.7337,  0.2842,  0.5973,  0.4844,  0.5811,  0.6310,\n",
       "          0.5097,  0.7347,  0.5804,  0.6681,  0.6587,  0.6985,  0.7594,  0.6966,\n",
       "          0.8075,  0.8348,  0.8739,  0.8189,  0.9008,  0.7661,  0.9679,  0.5854,\n",
       "          0.6219,  0.3453,  0.6477,  0.6709,  0.6299,  0.6548,  0.3300,  0.4896,\n",
       "          0.3027,  0.4301,  0.3639,  0.2435,  0.2734, -0.0101, -0.2588, -0.4587,\n",
       "          0.1145, -0.9049]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.scalar_timewarper.timewarp_parameter_encoder.encode(ydata[(0,1),],tdata[(0,1),])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "296aa664",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion_model_input torch.Size([400, 1])\n",
      "after fc:  torch.Size([400, 500])\n",
      "after fc:  torch.Size([400, 500])\n",
      "after fc:  torch.Size([400, 64])\n"
     ]
    }
   ],
   "source": [
    "answer = model.model.decoder.decode(emb[(0,1),],tdata[(0,1),]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a7820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123b074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
