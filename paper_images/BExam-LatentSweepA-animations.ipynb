{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c99de27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.619243Z",
     "start_time": "2023-09-27T14:36:06.987341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travers/miniconda3/envs/timewarpvae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timewarp_lib.load_model as lm\n",
    "import timewarp_lib.train_utils as tu\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79498222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.624218Z",
     "start_time": "2023-09-27T14:36:13.621445Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9234e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.630664Z",
     "start_time": "2023-09-27T14:36:13.628445Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "####clean_model_dirs = [\"../results/overnight/20230921-093159.705744/savedmodel\"] # TenDTWModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ba9e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.637330Z",
     "start_time": "2023-09-27T14:36:13.635016Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d7bc2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:36:13.666030Z",
     "start_time": "2023-09-27T14:36:13.638892Z"
    }
   },
   "outputs": [],
   "source": [
    "datatype = \"train\"\n",
    "dtype=torch.float\n",
    "device=\"cpu\"\n",
    "batch_size=100\n",
    "training_data_timing_noise=0\n",
    "TRAJLEN=200\n",
    "\n",
    "dataName = \"../data/trainTest2DLetterARescaled.npz\"\n",
    "# the datafile has information on how the data was cleaned\n",
    "# the learned/applied model is on clean data\n",
    "# so we need to convert back to trajectory data\n",
    "rawdata = loaded_data_dict = np.load(dataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21561f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_this_model(modelname,train):\n",
    "    model = lm.LoadedModel(modelname)\n",
    "    ts = torch.tensor(np.linspace(0,1,train.shape[1]).reshape((1,train.shape[1],1)), dtype=torch.float).expand((train.shape[0],train.shape[1],1))\n",
    "    recons, mu, logvar, scaled_ts = model.model.noiseless_forward(train,ts)\n",
    "\n",
    "    return mu, recons, scaled_ts, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b9a4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def plot_1d_sweep(modelname, sweepaxis=0,num_trajs_to_plot=101):\n",
    "    cmap = plt.get_cmap(\"viridis\")\n",
    "    model = lm.LoadedModel(modelname)\n",
    "    print(model.modeldata)\n",
    "    # Create a new plot\n",
    "    model_data_path = str(model.modeldata[\"datafile\"])\n",
    "    modeldata_info = np.load(\"../\"+ model_data_path)\n",
    "    pose_scaling = modeldata_info[\"pose_scaling\"]\n",
    "    pose_mean = modeldata_info[\"pose_mean\"]\n",
    "    train = torch.tensor(rawdata[\"train\"],dtype=torch.float)\n",
    "    embed, recons, scaled_ts, model = load_this_model(modelname,train)\n",
    "    #print(embed)\n",
    "    latent_dim = model.modeldata[\"latent_dim\"]\n",
    "    num_timesteps = TRAJLEN\n",
    "    \n",
    "    scaled_ts = scaled_ts.detach().cpu().numpy()\n",
    "    npts = np.mean(scaled_ts,axis=0,keepdims=True)\n",
    "    scaled_ts = torch.tensor(npts,dtype=torch.float).expand((num_trajs_to_plot,num_timesteps,1))\n",
    "    \n",
    "    embednp = embed.detach().cpu().numpy()\n",
    "    sweep_embed = np.zeros(shape=(num_trajs_to_plot,latent_dim))    \n",
    "    for i in range(latent_dim):\n",
    "        sweep_embed[:,i] = np.median(embednp[:,i])\n",
    "    med_sweep_embed = torch.tensor(sweep_embed,dtype=torch.float)\n",
    "    med_traj = model.model.decoder.decode(med_sweep_embed[:1],scaled_ts[:1]).detach().numpy()\n",
    "\n",
    "    unscale_recons = med_traj\n",
    "    \n",
    "    #xs = unscale_recons[0,:TRAJLEN,0]\n",
    "    #ys = unscale_recons[0,:TRAJLEN,1]\n",
    "    #zs = unscale_recons[0,:TRAJLEN,2]\n",
    "    #axes.plot(xs,ys,zs,color=\"k\",linewidth=10)\n",
    "    #\n",
    "    median_result_trajs = model.model.decoder.decode(med_sweep_embed,scaled_ts).detach().numpy()\n",
    "    for i in range(latent_dim):\n",
    "        sweep_embed[:,i] = np.median(embednp[:,i])\n",
    "    sweep_embed[:,sweepaxis] = np.percentile(embednp[:,sweepaxis],np.linspace(2,98,num_trajs_to_plot).astype(int))\n",
    "    \n",
    "    sweep_embed = torch.tensor(sweep_embed,dtype=torch.float)\n",
    "    \n",
    "    result_trajs = model.model.decoder.decode(sweep_embed,scaled_ts).detach().numpy()\n",
    "\n",
    "    \n",
    "    sweep_embed = sweep_embed.detach().cpu().numpy()\n",
    "    recons = result_trajs#.detach().cpu().numpy()\n",
    "    train = train.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # matplotlib doesn't do raytracing, so we gotta manually plot in order\n",
    "    \n",
    "    minembed = np.min(sweep_embed[:,sweepaxis]) if sweep_embed.shape[1]>0 else 0\n",
    "    maxembed = np.max(sweep_embed[:,sweepaxis]) if sweep_embed.shape[1]>0 else 0\n",
    "    order = np.argsort(-sweep_embed[:,sweepaxis]) if model.modeldata[\"latent_dim\"] > 0 else np.arange(len(train))\n",
    "    for rto, raytracing_order in enumerate([order]):#,np.argsort(embed.flatten())]):\n",
    "        for name,data in [(\"Reconstructed\",result_trajs)]: #\n",
    "            unscale_recons = data\n",
    "\n",
    "            for framenumber, trajid in enumerate(raytracing_order):\n",
    "                figure = plt.figure(figsize=(10,10))\n",
    "                axes = plt.axes()\n",
    "                xs = unscale_recons[trajid,:TRAJLEN,0]\n",
    "                ys = unscale_recons[trajid,:TRAJLEN,1]\n",
    "                #colorval = cmap((sweep_embed[trajid,sweepaxis]-minembed)/(maxembed-minembed)) if embed.shape[1] > 0  else \"black\"\n",
    "                \n",
    "                #colorval = (colorval[0],colorval[1],colorval[2],0.8)\n",
    "                # backfill in white first\n",
    "                #axes.plot(xs,ys,color=(1,1,1),linewidth=7)\n",
    "                axes.plot(xs,ys,color=\"black\",linewidth=7)\n",
    "\n",
    "                plt.xlim(-3,-3+6)\n",
    "                plt.ylim(-3,-3+6)\n",
    "                plt.axis(\"off\")\n",
    "                figure.savefig(f\"animatedLatentLetterA/latent{sweepaxis}-frame{framenumber}.png\", bbox_inches='tight', pad_inches=0.1)\n",
    "                #plt.show()\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "981e66d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "{'dtype_string': array('float', dtype='<U5'), 'datafile': array('data/trainTest2DLetterARescaled.npz', dtype='<U35'), 'model_save_dir': array('results/rescaled/20231011-003229.166126/savedmodel', dtype='<U50'), 'num_epochs': array(20000), 'latent_dim': array(16), 'device': array('cuda', dtype='<U4'), 'dtype': torch.float32, 'traj_len': array(200), 'traj_channels': array(2), 'beta': array(0.001), 'training_data_added_timing_noise': array(0.1), 'logname': array('results/rescaled/20231011-003229.166126/log', dtype='<U43'), 'batch_size': array(64), 'log_to_wandb_name': array('rescaled', dtype='<U8'), 'scalar_timewarper_name': array('modeled_scalar_timewarper', dtype='<U25'), 'scaltw_granularity': array(50), 'scaltw_emb_conv_layers_channels': array([16, 32, 32, 64, 64, 64]), 'scaltw_emb_conv_layers_strides': array([1, 2, 1, 2, 1, 2]), 'scaltw_emb_conv_layers_kernel_sizes': array([3, 3, 3, 3, 3, 3]), 'scaltw_emb_fc_layers_num_features': array([], dtype=float64), 'encoder_name': array('convolutional_encoder', dtype='<U21'), 'emb_nonlinearity': array('ReLU', dtype='<U4'), 'emb_conv_layers_channels': array([16, 32, 64, 32]), 'emb_conv_layers_strides': array([1, 2, 2, 2]), 'emb_conv_layers_kernel_sizes': array([3, 3, 3, 3]), 'emb_fc_layers_num_features': array([], dtype=float64), 'emb_dropout_probability': array(0.), 'decoder_name': array('functional_decoder_complicated', dtype='<U30'), 'dec_template_motion_hidden_layers': array([500, 500]), 'dec_complicated_function_hidden_dims': array([200]), 'dec_complicated_function_latent_size': array(64), 'dec_template_custom_initialization_grad_t': array(10.), 'dec_template_use_custom_initialization': array(True), 'dec_template_custom_initialization_t_intercept_padding': array(0.1), 'dec_complicated_only_side_latent': array(True), 'vector_timewarper_name': array('identity_vector_timewarper', dtype='<U26'), 'step_each_batch': array(True), 'learn_decoder_variance': array(False), 'dec_initial_log_noise_estimate': array(-4.60517019), 'pre_time_learning_epochs': array(0), 'scalar_timewarping_lr': array(0.0001), 'scalar_timewarping_eps': array(1.e-06), 'scalar_timewarper_timereg': array(0.05), 'scalar_timewarper_endpointreg': array(0), 'scaltw_min_canonical_time': array(0.), 'scaltw_max_canonical_time': array(1.), 'dec_use_softplus': array(False), 'dec_use_elu': array(True), 'decoding_l2_weight_decay': array(0.), 'decoding_spatial_derivative_regularization': array(0.), 'dec_spatial_regularization_factor': array(1.), 'decoding_lr': array(0.0001), 'encoding_lr': array(0.0001), 'decoding_eps': array(0.0001), 'encoding_eps': array(0.0001), 'useAdam': array(True), 'curv_loss_penalty_weight': array(0.)}\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 32, 96])\n",
      "did convolution  torch.Size([125, 64, 47])\n",
      "did convolution  torch.Size([125, 64, 45])\n",
      "did convolution  torch.Size([125, 64, 22])\n",
      "flattened torch.Size([125, 1408])\n",
      "final torch.Size([125, 50])\n",
      "before transpose torch.Size([125, 200, 2])\n",
      "after transpose torch.Size([125, 2, 200])\n",
      "did convolution  torch.Size([125, 16, 198])\n",
      "did convolution  torch.Size([125, 32, 98])\n",
      "did convolution  torch.Size([125, 64, 48])\n",
      "did convolution  torch.Size([125, 32, 23])\n",
      "flattened torch.Size([125, 736])\n",
      "final torch.Size([125, 16])\n",
      "motion_model_input torch.Size([25000, 1])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 500])\n",
      "after fc:  torch.Size([25000, 64])\n",
      "motion_model_input torch.Size([200, 1])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 500])\n",
      "after fc:  torch.Size([200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n",
      "motion_model_input torch.Size([20200, 1])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 500])\n",
      "after fc:  torch.Size([20200, 64])\n"
     ]
    }
   ],
   "source": [
    "for latdimplot in range(16):\n",
    "    plot_1d_sweep(\"../results/rescaled/20231011-003229.166126/savedmodel\",latdimplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa85af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
